{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Continueing training?\n",
    "continued = False\n",
    "checkpoint_file_to_use = None #Example: 'ckpt_model_01_run01/hourly/model-9350'\n",
    "\n",
    "#If training from step 0\n",
    "#############################\n",
    "naming = 'model_04_run02'\n",
    "#############################\n",
    "variables = {\n",
    "    'modify_images': False,\n",
    "    'crop_images': False,\n",
    "    'enlarge_images': False,\n",
    "    'before_flatten_image_side_size': 4, #Need to calculate\n",
    "    'first_hidden_layer_features': 384,\n",
    "    'weights_stddev': 0.015,\n",
    "    'biases_initial': 0.1,\n",
    "    'dropout_train_keep_prob': 1.0,\n",
    "    'learning_rate_initial': 0.1,\n",
    "    'learning_rate_decay_steps': int(10000000),\n",
    "    'learning_rate_decay': 1.0,\n",
    "    'start_step_early_stopping': 150000,\n",
    "    'early_stopping_patience': 0.1,\n",
    "    'batch_size': 200,\n",
    "    'max_steps': 100000000,\n",
    "    'average_n_validation_accuracy': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create accuracy_log to pickle and directories for TensorBoard and checkpoint\n",
    "accuracy_log = prep_accuracy_log(continued, checkpoint_file_to_use, naming, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get data and labels\n",
    "(train_data, validation_data, test_data, train_labels, validation_labels, test_labels) = get_data_and_labels(accuracy_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build a model\n",
    "crop_images = accuracy_log['variables']['crop_images']\n",
    "modify_images = accuracy_log['variables']['modify_images']\n",
    "weights_stddev = accuracy_log['variables']['weights_stddev']\n",
    "biases_initial = accuracy_log['variables']['biases_initial']\n",
    "input_image_side_size = accuracy_log['variables']['input_image_side_size']\n",
    "crop_to_side_size = accuracy_log['variables']['crop_to_side_size']\n",
    "before_flatten_image_side_size = accuracy_log['variables']['before_flatten_image_side_size']\n",
    "first_hidden_layer_features = accuracy_log['variables']['first_hidden_layer_features']\n",
    "learning_rate_initial = accuracy_log['variables']['learning_rate_initial']\n",
    "learning_rate_decay_steps = accuracy_log['variables']['learning_rate_decay_steps']\n",
    "learning_rate_decay = accuracy_log['variables']['learning_rate_decay']\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    data = tf.placeholder(tf.float32, [None, input_image_side_size, input_image_side_size, 3])\n",
    "    labels = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    if crop_images & modify_images:\n",
    "        data_v2 = tf.cond(is_training, lambda: random_modify(data, crop_to_side_size), lambda: crop_center(data, crop_to_side_size))\n",
    "    elif (not crop_images) & modify_images:\n",
    "        data_v2 = tf.cond(is_training, lambda: random_modify_no_crop(data), lambda: tf.identity(data))\n",
    "    elif crop_images & (not modify_images):\n",
    "        data_v2 = tf.cond(is_training, lambda: random_crop(data, crop_to_side_size), lambda: crop_center(data, crop_to_side_size))\n",
    "    else:\n",
    "        data_v2 = tf.identity(data)\n",
    "\n",
    "    data_v2 = batch_normalize(data_v2, is_training=is_training, global_step=global_step, scope='bn_data_v2')\n",
    "    W_conv1 = weight_variable([3, 3, 3, 64], weights_stddev, 'W_conv1')\n",
    "    b_conv1 = bias_variable(biases_initial, [64], 'b_conv1')\n",
    "    conv1 = conv2d(data_v2, W_conv1) + b_conv1\n",
    "    conv1_relu = tf.nn.relu(conv1)\n",
    "    pool1 = max_pool_3x3_stride2(conv1_relu)\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "    norm1 = batch_normalize(norm1, is_training=is_training, global_step=global_step, scope='bn_norm1')\n",
    "    W_conv2 = weight_variable([3, 3, 64, 64], weights_stddev, 'W_conv2')\n",
    "    b_conv2 = bias_variable(biases_initial, [64], 'b_conv2')\n",
    "    conv2 = conv2d(norm1, W_conv2) + b_conv2\n",
    "    conv2_relu = tf.nn.relu(conv2)\n",
    "    pool2 = max_pool_3x3_stride2(conv2_relu)\n",
    "    norm2 = tf.nn.lrn(pool2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "    norm2 = batch_normalize(norm2, is_training=is_training, global_step=global_step, scope='bn_norm2')\n",
    "    W_conv3 = weight_variable([3, 3, 64, 128], weights_stddev, 'W_conv3')\n",
    "    b_conv3 = bias_variable(biases_initial, [128], 'b_conv3')\n",
    "    conv3 = conv2d(norm2, W_conv3) + b_conv3\n",
    "    conv3_relu = tf.nn.relu(conv3)\n",
    "    pool3 = max_pool_3x3_stride2(conv3_relu)\n",
    "    norm3 = tf.nn.lrn(pool3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    norm3_flat = tf.reshape(norm3, [-1, before_flatten_image_side_size*before_flatten_image_side_size*128])\n",
    "\n",
    "    norm3_flat = batch_normalize(norm3_flat, is_training=is_training, global_step=global_step, scope='bn_norm3_flat')\n",
    "    W_fc1 = weight_variable([before_flatten_image_side_size*before_flatten_image_side_size*128, first_hidden_layer_features], weights_stddev, 'W_fc1')\n",
    "    b_fc1 = bias_variable(biases_initial, [first_hidden_layer_features], 'b_fc1')\n",
    "    fc1 = tf.matmul(norm3_flat, W_fc1) + b_fc1\n",
    "    fc1_relu = tf.nn.relu(fc1)\n",
    "\n",
    "    fc1_relu = batch_normalize(fc1_relu, is_training=is_training, global_step=global_step, scope='bn_fc1_relu')    \n",
    "    W_fc2 = weight_variable([first_hidden_layer_features, int(first_hidden_layer_features/2)], weights_stddev, 'W_fc2')\n",
    "    b_fc2 = bias_variable(biases_initial, [first_hidden_layer_features/2], 'b_fc2')\n",
    "    fc2 = tf.matmul(fc1_relu, W_fc2) + b_fc2\n",
    "    fc2_relu = tf.nn.relu(fc2)\n",
    "\n",
    "    fc2_relu = batch_normalize(fc2_relu, is_training=is_training, global_step=global_step, scope='bn_fc2_relu')\n",
    "    W_fc3 = weight_variable([int(first_hidden_layer_features/2), 10], weights_stddev, 'W_fc3')\n",
    "    b_fc3 = bias_variable(biases_initial, [10], 'b_fc3')\n",
    "    logits = tf.matmul(fc2_relu, W_fc3) + b_fc3\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(learning_rate_initial, global_step, learning_rate_decay_steps, \n",
    "                                               learning_rate_decay, staircase=True)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    tf.summary.scalar('training_accuracy', accuracy)\n",
    "    \n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "    \n",
    "    summarizer = tf.summary.merge_all()\n",
    "    \n",
    "graph_variables = {'graph': graph, \n",
    "                   'optimizer': optimizer, \n",
    "                   'summarizer': summarizer, \n",
    "                   'data': data, \n",
    "                   'labels': labels, \n",
    "                   'keep_prob': keep_prob, \n",
    "                   'is_training': is_training, \n",
    "                   'correct_prediction': correct_prediction,\n",
    "                   'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING   START @ 2016-12-24 01:58:09.081502\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-0 >> ave validation accuracy 0.10220\n",
      "STEP       0 END @ 2016-12-24 01:58:17.403670, training accuracy 0.12500, ave validation accuracy 0.10220\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-200 >> ave validation accuracy 0.11493\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-300 >> ave validation accuracy 0.11500\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-500 >> ave validation accuracy 0.11667\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1000 >> ave validation accuracy 0.12321\n",
      "STEP    1000 END @ 2016-12-24 01:59:29.350671, training accuracy 0.21500, ave validation accuracy 0.12321\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1100 >> ave validation accuracy 0.13761\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1200 >> ave validation accuracy 0.15480\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1300 >> ave validation accuracy 0.16759\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1400 >> ave validation accuracy 0.20061\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1500 >> ave validation accuracy 0.22459\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1600 >> ave validation accuracy 0.25537\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1700 >> ave validation accuracy 0.30020\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1800 >> ave validation accuracy 0.33945\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-1900 >> ave validation accuracy 0.38037\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2000 >> ave validation accuracy 0.42227\n",
      "STEP    2000 END @ 2016-12-24 02:01:07.562297, training accuracy 0.75500, ave validation accuracy 0.42227\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2100 >> ave validation accuracy 0.47525\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2200 >> ave validation accuracy 0.51630\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2300 >> ave validation accuracy 0.56595\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2400 >> ave validation accuracy 0.61115\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2500 >> ave validation accuracy 0.64346\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2600 >> ave validation accuracy 0.67230\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2700 >> ave validation accuracy 0.69695\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2800 >> ave validation accuracy 0.71912\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-2900 >> ave validation accuracy 0.73359\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3000 >> ave validation accuracy 0.74252\n",
      "STEP    3000 END @ 2016-12-24 02:02:47.131939, training accuracy 0.98000, ave validation accuracy 0.74252\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3100 >> ave validation accuracy 0.75004\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3200 >> ave validation accuracy 0.75974\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3300 >> ave validation accuracy 0.76768\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3400 >> ave validation accuracy 0.77429\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3500 >> ave validation accuracy 0.77928\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3600 >> ave validation accuracy 0.78364\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3700 >> ave validation accuracy 0.78733\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3800 >> ave validation accuracy 0.79110\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-3900 >> ave validation accuracy 0.79479\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4000 >> ave validation accuracy 0.79701\n",
      "STEP    4000 END @ 2016-12-24 02:04:25.096636, training accuracy 1.00000, ave validation accuracy 0.79701\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4100 >> ave validation accuracy 0.79910\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4200 >> ave validation accuracy 0.80036\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4300 >> ave validation accuracy 0.80143\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4400 >> ave validation accuracy 0.80219\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4500 >> ave validation accuracy 0.80289\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4600 >> ave validation accuracy 0.80350\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4700 >> ave validation accuracy 0.80391\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4800 >> ave validation accuracy 0.80419\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-4900 >> ave validation accuracy 0.80429\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5000 >> ave validation accuracy 0.80443\n",
      "STEP    5000 END @ 2016-12-24 02:06:03.185141, training accuracy 1.00000, ave validation accuracy 0.80443\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5100 >> ave validation accuracy 0.80481\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5200 >> ave validation accuracy 0.80498\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5300 >> ave validation accuracy 0.80499\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5400 >> ave validation accuracy 0.80518\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5500 >> ave validation accuracy 0.80523\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5600 >> ave validation accuracy 0.80540\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-5800 >> ave validation accuracy 0.80541\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-6000 >> ave validation accuracy 0.80544\n",
      "STEP    6000 END @ 2016-12-24 02:07:32.435613, training accuracy 1.00000, ave validation accuracy 0.80544\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-6100 >> ave validation accuracy 0.80550\n",
      "STEP    7000 END @ 2016-12-24 02:08:32.109681, training accuracy 1.00000, ave validation accuracy 0.80503\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-8000 >> ave validation accuracy 0.80551\n",
      "STEP    8000 END @ 2016-12-24 02:09:31.751110, training accuracy 1.00000, ave validation accuracy 0.80551\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-8100 >> ave validation accuracy 0.80571\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-8200 >> ave validation accuracy 0.80584\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-9000 >> ave validation accuracy 0.80585\n",
      "STEP    9000 END @ 2016-12-24 02:10:38.507087, training accuracy 1.00000, ave validation accuracy 0.80585\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-9100 >> ave validation accuracy 0.80603\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-9200 >> ave validation accuracy 0.80618\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-9400 >> ave validation accuracy 0.80623\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-9500 >> ave validation accuracy 0.80625\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-9600 >> ave validation accuracy 0.80638\n",
      "STEP   10000 END @ 2016-12-24 02:11:55.452549, training accuracy 1.00000, ave validation accuracy 0.80611\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-10300 >> ave validation accuracy 0.80648\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-10400 >> ave validation accuracy 0.80651\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-10500 >> ave validation accuracy 0.80655\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-10600 >> ave validation accuracy 0.80663\n",
      "STEP   11000 END @ 2016-12-24 02:13:07.326208, training accuracy 1.00000, ave validation accuracy 0.80630\n",
      "STEP   12000 END @ 2016-12-24 02:14:01.964383, training accuracy 1.00000, ave validation accuracy 0.80585\n",
      "STEP   13000 END @ 2016-12-24 02:14:56.499568, training accuracy 1.00000, ave validation accuracy 0.80636\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-13500 >> ave validation accuracy 0.80664\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-13900 >> ave validation accuracy 0.80668\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-14000 >> ave validation accuracy 0.80685\n",
      "STEP   14000 END @ 2016-12-24 02:16:03.272214, training accuracy 1.00000, ave validation accuracy 0.80685\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-14100 >> ave validation accuracy 0.80693\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-14300 >> ave validation accuracy 0.80703\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-14500 >> ave validation accuracy 0.80709\n",
      "<< best model so far is saved in ckpt_model_04_run02/best/model-14600 >> ave validation accuracy 0.80718\n",
      "STEP   15000 END @ 2016-12-24 02:17:15.171422, training accuracy 1.00000, ave validation accuracy 0.80680\n",
      "STEP   16000 END @ 2016-12-24 02:18:09.888638, training accuracy 1.00000, ave validation accuracy 0.80700\n",
      "STEP   17000 END @ 2016-12-24 02:19:04.470201, training accuracy 1.00000, ave validation accuracy 0.80668\n",
      "STEP   18000 END @ 2016-12-24 02:19:59.167083, training accuracy 1.00000, ave validation accuracy 0.80651\n",
      "STEP   19000 END @ 2016-12-24 02:20:53.736683, training accuracy 1.00000, ave validation accuracy 0.80630\n",
      "STEP   20000 END @ 2016-12-24 02:21:48.299493, training accuracy 1.00000, ave validation accuracy 0.80671\n",
      "STEP   21000 END @ 2016-12-24 02:22:42.936651, training accuracy 1.00000, ave validation accuracy 0.80671\n",
      "STEP   22000 END @ 2016-12-24 02:23:37.533382, training accuracy 1.00000, ave validation accuracy 0.80625\n",
      "STEP   23000 END @ 2016-12-24 02:24:32.103209, training accuracy 1.00000, ave validation accuracy 0.80603\n",
      "STEP   24000 END @ 2016-12-24 02:25:26.643022, training accuracy 1.00000, ave validation accuracy 0.80658\n",
      "STEP   25000 END @ 2016-12-24 02:26:21.268969, training accuracy 1.00000, ave validation accuracy 0.80624\n",
      "STEP   26000 END @ 2016-12-24 02:27:15.827142, training accuracy 1.00000, ave validation accuracy 0.80629\n",
      "STEP   27000 END @ 2016-12-24 02:28:10.210296, training accuracy 1.00000, ave validation accuracy 0.80574\n",
      "STEP   28000 END @ 2016-12-24 02:29:04.770827, training accuracy 1.00000, ave validation accuracy 0.80603\n",
      "STEP   29000 END @ 2016-12-24 02:29:59.382350, training accuracy 1.00000, ave validation accuracy 0.80643\n",
      "STEP   30000 END @ 2016-12-24 02:30:54.056076, training accuracy 1.00000, ave validation accuracy 0.80615\n",
      "STEP   31000 END @ 2016-12-24 02:31:48.737862, training accuracy 1.00000, ave validation accuracy 0.80635\n",
      "STEP   32000 END @ 2016-12-24 02:32:43.304988, training accuracy 1.00000, ave validation accuracy 0.80656\n",
      "STEP   33000 END @ 2016-12-24 02:33:38.015395, training accuracy 1.00000, ave validation accuracy 0.80625\n",
      "STEP   34000 END @ 2016-12-24 02:34:32.654853, training accuracy 1.00000, ave validation accuracy 0.80591\n",
      "STEP   35000 END @ 2016-12-24 02:35:27.170485, training accuracy 1.00000, ave validation accuracy 0.80608\n",
      "STEP   36000 END @ 2016-12-24 02:36:21.734881, training accuracy 1.00000, ave validation accuracy 0.80598\n",
      "STEP   37000 END @ 2016-12-24 02:37:16.195496, training accuracy 1.00000, ave validation accuracy 0.80610\n",
      "STEP   38000 END @ 2016-12-24 02:38:10.686053, training accuracy 1.00000, ave validation accuracy 0.80596\n",
      "STEP   39000 END @ 2016-12-24 02:39:05.244412, training accuracy 1.00000, ave validation accuracy 0.80643\n",
      "STEP   40000 END @ 2016-12-24 02:39:59.771741, training accuracy 1.00000, ave validation accuracy 0.80635\n",
      "STEP   41000 END @ 2016-12-24 02:40:54.382686, training accuracy 1.00000, ave validation accuracy 0.80584\n",
      "STEP   42000 END @ 2016-12-24 02:41:49.005616, training accuracy 1.00000, ave validation accuracy 0.80598\n",
      "STEP   43000 END @ 2016-12-24 02:42:43.558195, training accuracy 1.00000, ave validation accuracy 0.80609\n",
      "STEP   44000 END @ 2016-12-24 02:43:38.252317, training accuracy 1.00000, ave validation accuracy 0.80610\n",
      "STEP   45000 END @ 2016-12-24 02:44:32.911406, training accuracy 1.00000, ave validation accuracy 0.80559\n",
      "STEP   46000 END @ 2016-12-24 02:45:27.503054, training accuracy 1.00000, ave validation accuracy 0.80580\n",
      "STEP   47000 END @ 2016-12-24 02:46:22.143199, training accuracy 1.00000, ave validation accuracy 0.80579\n",
      "STEP   48000 END @ 2016-12-24 02:47:16.787169, training accuracy 1.00000, ave validation accuracy 0.80614\n",
      "STEP   49000 END @ 2016-12-24 02:48:11.402904, training accuracy 1.00000, ave validation accuracy 0.80586\n",
      "STEP   50000 END @ 2016-12-24 02:49:06.008092, training accuracy 1.00000, ave validation accuracy 0.80521\n",
      "STEP   51000 END @ 2016-12-24 02:50:00.539830, training accuracy 1.00000, ave validation accuracy 0.80563\n",
      "STEP   52000 END @ 2016-12-24 02:50:55.107816, training accuracy 1.00000, ave validation accuracy 0.80559\n",
      "STEP   53000 END @ 2016-12-24 02:51:49.732619, training accuracy 1.00000, ave validation accuracy 0.80569\n",
      "STEP   54000 END @ 2016-12-24 02:52:44.266752, training accuracy 1.00000, ave validation accuracy 0.80529\n",
      "STEP   55000 END @ 2016-12-24 02:53:38.647249, training accuracy 1.00000, ave validation accuracy 0.80536\n",
      "STEP   56000 END @ 2016-12-24 02:54:33.313959, training accuracy 1.00000, ave validation accuracy 0.80535\n",
      "STEP   57000 END @ 2016-12-24 02:55:27.811288, training accuracy 1.00000, ave validation accuracy 0.80524\n",
      "STEP   58000 END @ 2016-12-24 02:56:22.387212, training accuracy 1.00000, ave validation accuracy 0.80529\n",
      "STEP   59000 END @ 2016-12-24 02:57:16.962408, training accuracy 1.00000, ave validation accuracy 0.80574\n",
      "<< hourly save at ckpt_model_04_run02/hourly/model-60000 and pickle_model_04_run02 >>\n",
      "STEP   60000 END @ 2016-12-24 02:58:16.425335, training accuracy 1.00000, ave validation accuracy 0.80595\n",
      "STEP   61000 END @ 2016-12-24 02:59:10.996471, training accuracy 1.00000, ave validation accuracy 0.80521\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-feafc4fc8124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinued\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/kumiko/cifar10/helper_functions.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(continued, graph_variables, accuracy_log, train_data, train_labels, validation_data, validation_labels)\u001b[0m\n\u001b[1;32m    251\u001b[0m             _, summary = sess.run([graph_variables['optimizer'], graph_variables['summarizer']], \n\u001b[1;32m    252\u001b[0m                                   feed_dict={graph_variables['data']: batch_data, graph_variables['labels']: batch_labels,\n\u001b[0;32m--> 253\u001b[0;31m                                              graph_variables['keep_prob']: accuracy_log['variables']['dropout_train_keep_prob'], graph_variables['is_training']: True})\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_every'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train(continued, graph_variables, accuracy_log, train_data, train_labels, validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< test accuracy 0.80200 >>\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "test_accuracy(graph_variables, accuracy_log, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
