{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Continueing training?\n",
    "continued = False\n",
    "checkpoint_file_to_use = None #Example: 'ckpt_model_01_run01/hourly/model-9350'\n",
    "\n",
    "#If training from step 0\n",
    "#############################\n",
    "naming = 'model_05_run01'\n",
    "#############################\n",
    "variables = {\n",
    "    'modify_images': False,\n",
    "    'crop_images': False,\n",
    "    'enlarge_images': False,\n",
    "    'before_flatten_image_side_size': 4, #Need to calculate\n",
    "    'first_hidden_layer_features': 384,\n",
    "    'weights_stddev': 0.015,\n",
    "    'biases_initial': 0.1,\n",
    "    'dropout_train_keep_prob': 0.5,\n",
    "    'learning_rate_initial': 0.1,\n",
    "    'learning_rate_decay_steps': int(10000000),\n",
    "    'learning_rate_decay': 1.0,\n",
    "    'start_step_early_stopping': 150000,\n",
    "    'early_stopping_patience': 0.1,\n",
    "    'batch_size': 200,\n",
    "    'max_steps': 100000000,\n",
    "    'average_n_validation_accuracy': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create accuracy_log to pickle and directories for TensorBoard and checkpoint\n",
    "accuracy_log = prep_accuracy_log(continued, checkpoint_file_to_use, naming, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get data and labels\n",
    "(train_data, validation_data, test_data, train_labels, validation_labels, test_labels) = get_data_and_labels(accuracy_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build a model\n",
    "crop_images = accuracy_log['variables']['crop_images']\n",
    "modify_images = accuracy_log['variables']['modify_images']\n",
    "weights_stddev = accuracy_log['variables']['weights_stddev']\n",
    "biases_initial = accuracy_log['variables']['biases_initial']\n",
    "input_image_side_size = accuracy_log['variables']['input_image_side_size']\n",
    "crop_to_side_size = accuracy_log['variables']['crop_to_side_size']\n",
    "before_flatten_image_side_size = accuracy_log['variables']['before_flatten_image_side_size']\n",
    "first_hidden_layer_features = accuracy_log['variables']['first_hidden_layer_features']\n",
    "learning_rate_initial = accuracy_log['variables']['learning_rate_initial']\n",
    "learning_rate_decay_steps = accuracy_log['variables']['learning_rate_decay_steps']\n",
    "learning_rate_decay = accuracy_log['variables']['learning_rate_decay']\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    data = tf.placeholder(tf.float32, [None, input_image_side_size, input_image_side_size, 3])\n",
    "    labels = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    if crop_images & modify_images:\n",
    "        data_v2 = tf.cond(is_training, lambda: random_modify(data, crop_to_side_size), lambda: crop_center(data, crop_to_side_size))\n",
    "    elif (not crop_images) & modify_images:\n",
    "        data_v2 = tf.cond(is_training, lambda: random_modify_no_crop(data), lambda: tf.identity(data))\n",
    "    elif crop_images & (not modify_images):\n",
    "        data_v2 = tf.cond(is_training, lambda: random_crop(data, crop_to_side_size), lambda: crop_center(data, crop_to_side_size))\n",
    "    else:\n",
    "        data_v2 = tf.identity(data)\n",
    "\n",
    "    data_v2 = batch_normalize(data_v2, is_training=is_training, global_step=global_step, scope='bn_data_v2')\n",
    "    W_conv1 = weight_variable([3, 3, 3, 64], weights_stddev, 'W_conv1')\n",
    "    b_conv1 = bias_variable(biases_initial, [64], 'b_conv1')\n",
    "    conv1 = conv2d(data_v2, W_conv1) + b_conv1\n",
    "    conv1_relu = tf.nn.relu(conv1)\n",
    "    pool1 = max_pool_3x3_stride2(conv1_relu)\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "    norm1 = batch_normalize(norm1, is_training=is_training, global_step=global_step, scope='bn_norm1')\n",
    "    W_conv2 = weight_variable([3, 3, 64, 64], weights_stddev, 'W_conv2')\n",
    "    b_conv2 = bias_variable(biases_initial, [64], 'b_conv2')\n",
    "    conv2 = conv2d(norm1, W_conv2) + b_conv2\n",
    "    conv2_relu = tf.nn.relu(conv2)\n",
    "    pool2 = max_pool_3x3_stride2(conv2_relu)\n",
    "    norm2 = tf.nn.lrn(pool2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "    norm2 = batch_normalize(norm2, is_training=is_training, global_step=global_step, scope='bn_norm2')\n",
    "    W_conv3 = weight_variable([3, 3, 64, 128], weights_stddev, 'W_conv3')\n",
    "    b_conv3 = bias_variable(biases_initial, [128], 'b_conv3')\n",
    "    conv3 = conv2d(norm2, W_conv3) + b_conv3\n",
    "    conv3_relu = tf.nn.relu(conv3)\n",
    "    pool3 = max_pool_3x3_stride2(conv3_relu)\n",
    "    norm3 = tf.nn.lrn(pool3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    norm3_flat = tf.reshape(norm3, [-1, before_flatten_image_side_size*before_flatten_image_side_size*128])\n",
    "\n",
    "    norm3_flat = batch_normalize(norm3_flat, is_training=is_training, global_step=global_step, scope='bn_norm3_flat')\n",
    "    norm3_flat_drop = tf.nn.dropout(norm3_flat, keep_prob)\n",
    "    W_fc1 = weight_variable([before_flatten_image_side_size*before_flatten_image_side_size*128, first_hidden_layer_features], weights_stddev, 'W_fc1')\n",
    "    b_fc1 = bias_variable(biases_initial, [first_hidden_layer_features], 'b_fc1')\n",
    "    fc1 = tf.matmul(norm3_flat_drop, W_fc1) + b_fc1\n",
    "    fc1_relu = tf.nn.relu(fc1)\n",
    "\n",
    "    fc1_relu = batch_normalize(fc1_relu, is_training=is_training, global_step=global_step, scope='bn_fc1_relu')    \n",
    "    fc1_relu_drop = tf.nn.dropout(fc1_relu, keep_prob)\n",
    "    W_fc2 = weight_variable([first_hidden_layer_features, int(first_hidden_layer_features/2)], weights_stddev, 'W_fc2')\n",
    "    b_fc2 = bias_variable(biases_initial, [first_hidden_layer_features/2], 'b_fc2')\n",
    "    fc2 = tf.matmul(fc1_relu_drop, W_fc2) + b_fc2\n",
    "    fc2_relu = tf.nn.relu(fc2)\n",
    "\n",
    "    fc2_relu = batch_normalize(fc2_relu, is_training=is_training, global_step=global_step, scope='bn_fc2_relu')\n",
    "    fc2_relu_drop = tf.nn.dropout(fc2_relu, keep_prob)\n",
    "    W_fc3 = weight_variable([int(first_hidden_layer_features/2), 10], weights_stddev, 'W_fc3')\n",
    "    b_fc3 = bias_variable(biases_initial, [10], 'b_fc3')\n",
    "    logits = tf.matmul(fc2_relu_drop, W_fc3) + b_fc3\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(learning_rate_initial, global_step, learning_rate_decay_steps, \n",
    "                                               learning_rate_decay, staircase=True)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    tf.summary.scalar('training_accuracy', accuracy)\n",
    "    \n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "    \n",
    "    summarizer = tf.summary.merge_all()\n",
    "    \n",
    "graph_variables = {'graph': graph, \n",
    "                   'optimizer': optimizer, \n",
    "                   'summarizer': summarizer, \n",
    "                   'data': data, \n",
    "                   'labels': labels, \n",
    "                   'keep_prob': keep_prob, \n",
    "                   'is_training': is_training, \n",
    "                   'correct_prediction': correct_prediction,\n",
    "                   'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING   START @ 2016-12-24 03:02:02.812802\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-0 >> ave validation accuracy 0.10140\n",
      "STEP       0 END @ 2016-12-24 03:02:10.810718, training accuracy 0.13500, ave validation accuracy 0.10140\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-100 >> ave validation accuracy 0.10480\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-200 >> ave validation accuracy 0.14607\n",
      "STEP    1000 END @ 2016-12-24 03:03:17.453490, training accuracy 0.13000, ave validation accuracy 0.10859\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-1400 >> ave validation accuracy 0.14816\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-1500 >> ave validation accuracy 0.17401\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-1600 >> ave validation accuracy 0.20462\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-1700 >> ave validation accuracy 0.24881\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-1800 >> ave validation accuracy 0.28151\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-1900 >> ave validation accuracy 0.32460\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2000 >> ave validation accuracy 0.37597\n",
      "STEP    2000 END @ 2016-12-24 03:04:49.466249, training accuracy 0.69500, ave validation accuracy 0.37597\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2100 >> ave validation accuracy 0.42032\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2200 >> ave validation accuracy 0.47446\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2300 >> ave validation accuracy 0.52534\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2400 >> ave validation accuracy 0.57254\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2500 >> ave validation accuracy 0.60787\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2600 >> ave validation accuracy 0.65139\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2700 >> ave validation accuracy 0.68464\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2800 >> ave validation accuracy 0.70916\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-2900 >> ave validation accuracy 0.73550\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3000 >> ave validation accuracy 0.75506\n",
      "STEP    3000 END @ 2016-12-24 03:06:40.441685, training accuracy 0.89000, ave validation accuracy 0.75506\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3100 >> ave validation accuracy 0.76580\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3200 >> ave validation accuracy 0.77393\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3300 >> ave validation accuracy 0.78031\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3400 >> ave validation accuracy 0.78775\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3500 >> ave validation accuracy 0.79028\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3600 >> ave validation accuracy 0.79270\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3700 >> ave validation accuracy 0.79349\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3800 >> ave validation accuracy 0.79618\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-3900 >> ave validation accuracy 0.79759\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4000 >> ave validation accuracy 0.79969\n",
      "STEP    4000 END @ 2016-12-24 03:08:28.479430, training accuracy 0.93000, ave validation accuracy 0.79969\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4100 >> ave validation accuracy 0.80076\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4200 >> ave validation accuracy 0.80270\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4300 >> ave validation accuracy 0.80460\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4400 >> ave validation accuracy 0.80610\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4500 >> ave validation accuracy 0.80898\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4600 >> ave validation accuracy 0.81016\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-4700 >> ave validation accuracy 0.81040\n",
      "STEP    5000 END @ 2016-12-24 03:10:01.570594, training accuracy 0.93000, ave validation accuracy 0.81011\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-5100 >> ave validation accuracy 0.81054\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-5600 >> ave validation accuracy 0.81058\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-5800 >> ave validation accuracy 0.81136\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6000 >> ave validation accuracy 0.81233\n",
      "STEP    6000 END @ 2016-12-24 03:11:18.205003, training accuracy 0.96000, ave validation accuracy 0.81233\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6100 >> ave validation accuracy 0.81344\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6200 >> ave validation accuracy 0.81523\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6300 >> ave validation accuracy 0.81536\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6400 >> ave validation accuracy 0.81606\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6500 >> ave validation accuracy 0.81665\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6700 >> ave validation accuracy 0.81688\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-6900 >> ave validation accuracy 0.81718\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7000 >> ave validation accuracy 0.81764\n",
      "STEP    7000 END @ 2016-12-24 03:12:56.202745, training accuracy 0.97000, ave validation accuracy 0.81764\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7100 >> ave validation accuracy 0.81903\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7200 >> ave validation accuracy 0.81930\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7300 >> ave validation accuracy 0.82068\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7400 >> ave validation accuracy 0.82241\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7500 >> ave validation accuracy 0.82338\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7600 >> ave validation accuracy 0.82450\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-7800 >> ave validation accuracy 0.82499\n",
      "STEP    8000 END @ 2016-12-24 03:14:27.641840, training accuracy 0.99500, ave validation accuracy 0.82463\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-8200 >> ave validation accuracy 0.82503\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-8300 >> ave validation accuracy 0.82514\n",
      "STEP    9000 END @ 2016-12-24 03:15:34.059790, training accuracy 1.00000, ave validation accuracy 0.82256\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-10000 >> ave validation accuracy 0.82708\n",
      "STEP   10000 END @ 2016-12-24 03:16:34.133733, training accuracy 0.98500, ave validation accuracy 0.82708\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-10300 >> ave validation accuracy 0.82791\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-10400 >> ave validation accuracy 0.82894\n",
      "STEP   11000 END @ 2016-12-24 03:17:40.564761, training accuracy 0.99500, ave validation accuracy 0.82844\n",
      "STEP   12000 END @ 2016-12-24 03:18:35.650711, training accuracy 0.99500, ave validation accuracy 0.82876\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-12100 >> ave validation accuracy 0.83011\n",
      "STEP   13000 END @ 2016-12-24 03:19:34.241390, training accuracy 0.99000, ave validation accuracy 0.82948\n",
      "STEP   14000 END @ 2016-12-24 03:20:29.187663, training accuracy 1.00000, ave validation accuracy 0.82893\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-15000 >> ave validation accuracy 0.83075\n",
      "STEP   15000 END @ 2016-12-24 03:21:30.572578, training accuracy 0.99500, ave validation accuracy 0.83075\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-15100 >> ave validation accuracy 0.83120\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-15200 >> ave validation accuracy 0.83185\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-15500 >> ave validation accuracy 0.83220\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-15600 >> ave validation accuracy 0.83290\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-15700 >> ave validation accuracy 0.83380\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-15800 >> ave validation accuracy 0.83411\n",
      "STEP   16000 END @ 2016-12-24 03:22:56.841763, training accuracy 1.00000, ave validation accuracy 0.83355\n",
      "STEP   17000 END @ 2016-12-24 03:23:51.771986, training accuracy 0.99500, ave validation accuracy 0.83265\n",
      "STEP   18000 END @ 2016-12-24 03:24:46.637409, training accuracy 0.99000, ave validation accuracy 0.83128\n",
      "STEP   19000 END @ 2016-12-24 03:25:41.486836, training accuracy 1.00000, ave validation accuracy 0.83010\n",
      "STEP   20000 END @ 2016-12-24 03:26:36.394827, training accuracy 1.00000, ave validation accuracy 0.83343\n",
      "STEP   21000 END @ 2016-12-24 03:27:31.362916, training accuracy 0.99500, ave validation accuracy 0.83284\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-21900 >> ave validation accuracy 0.83445\n",
      "STEP   22000 END @ 2016-12-24 03:28:32.597917, training accuracy 1.00000, ave validation accuracy 0.83405\n",
      "STEP   23000 END @ 2016-12-24 03:29:27.447343, training accuracy 1.00000, ave validation accuracy 0.83195\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-24000 >> ave validation accuracy 0.83471\n",
      "STEP   24000 END @ 2016-12-24 03:30:27.188192, training accuracy 1.00000, ave validation accuracy 0.83471\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-24700 >> ave validation accuracy 0.83493\n",
      "STEP   25000 END @ 2016-12-24 03:31:26.979520, training accuracy 1.00000, ave validation accuracy 0.83409\n",
      "STEP   26000 END @ 2016-12-24 03:32:21.656328, training accuracy 1.00000, ave validation accuracy 0.83335\n",
      "STEP   27000 END @ 2016-12-24 03:33:16.486455, training accuracy 1.00000, ave validation accuracy 0.83325\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-27900 >> ave validation accuracy 0.83610\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-28000 >> ave validation accuracy 0.83664\n",
      "STEP   28000 END @ 2016-12-24 03:34:22.571255, training accuracy 1.00000, ave validation accuracy 0.83664\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-28300 >> ave validation accuracy 0.83673\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-28400 >> ave validation accuracy 0.83743\n",
      "<< best model so far is saved in ckpt_model_05_run01/best/model-28500 >> ave validation accuracy 0.83748\n",
      "STEP   29000 END @ 2016-12-24 03:35:33.505184, training accuracy 1.00000, ave validation accuracy 0.83558\n",
      "STEP   30000 END @ 2016-12-24 03:36:28.256332, training accuracy 1.00000, ave validation accuracy 0.83598\n",
      "STEP   31000 END @ 2016-12-24 03:37:23.006824, training accuracy 1.00000, ave validation accuracy 0.83423\n",
      "STEP   32000 END @ 2016-12-24 03:38:17.801503, training accuracy 1.00000, ave validation accuracy 0.83395\n",
      "STEP   33000 END @ 2016-12-24 03:39:12.621598, training accuracy 1.00000, ave validation accuracy 0.83511\n",
      "STEP   34000 END @ 2016-12-24 03:40:07.356457, training accuracy 1.00000, ave validation accuracy 0.83406\n",
      "STEP   35000 END @ 2016-12-24 03:41:02.238468, training accuracy 1.00000, ave validation accuracy 0.83436\n",
      "STEP   36000 END @ 2016-12-24 03:41:57.049710, training accuracy 1.00000, ave validation accuracy 0.83476\n",
      "STEP   37000 END @ 2016-12-24 03:42:51.741235, training accuracy 1.00000, ave validation accuracy 0.83555\n",
      "STEP   38000 END @ 2016-12-24 03:43:46.427276, training accuracy 1.00000, ave validation accuracy 0.83688\n",
      "STEP   39000 END @ 2016-12-24 03:44:41.143509, training accuracy 1.00000, ave validation accuracy 0.83386\n",
      "STEP   40000 END @ 2016-12-24 03:45:35.970804, training accuracy 1.00000, ave validation accuracy 0.83315\n",
      "STEP   41000 END @ 2016-12-24 03:46:30.627857, training accuracy 0.99500, ave validation accuracy 0.83421\n",
      "STEP   42000 END @ 2016-12-24 03:47:25.437835, training accuracy 1.00000, ave validation accuracy 0.83521\n",
      "STEP   43000 END @ 2016-12-24 03:48:20.205623, training accuracy 1.00000, ave validation accuracy 0.83551\n",
      "STEP   44000 END @ 2016-12-24 03:49:14.968648, training accuracy 1.00000, ave validation accuracy 0.83551\n",
      "STEP   45000 END @ 2016-12-24 03:50:09.862725, training accuracy 1.00000, ave validation accuracy 0.83654\n",
      "STEP   46000 END @ 2016-12-24 03:51:04.625623, training accuracy 1.00000, ave validation accuracy 0.83653\n",
      "STEP   47000 END @ 2016-12-24 03:51:59.324317, training accuracy 1.00000, ave validation accuracy 0.83544\n",
      "STEP   48000 END @ 2016-12-24 03:52:54.035304, training accuracy 1.00000, ave validation accuracy 0.83593\n",
      "STEP   49000 END @ 2016-12-24 03:53:48.855316, training accuracy 1.00000, ave validation accuracy 0.83580\n",
      "STEP   50000 END @ 2016-12-24 03:54:43.530440, training accuracy 1.00000, ave validation accuracy 0.83571\n",
      "STEP   51000 END @ 2016-12-24 03:55:38.228014, training accuracy 1.00000, ave validation accuracy 0.83590\n",
      "STEP   52000 END @ 2016-12-24 03:56:32.942493, training accuracy 1.00000, ave validation accuracy 0.83676\n",
      "STEP   53000 END @ 2016-12-24 03:57:27.600801, training accuracy 1.00000, ave validation accuracy 0.83575\n",
      "STEP   54000 END @ 2016-12-24 03:58:22.283885, training accuracy 1.00000, ave validation accuracy 0.83699\n",
      "STEP   55000 END @ 2016-12-24 03:59:16.992507, training accuracy 1.00000, ave validation accuracy 0.83584\n",
      "STEP   56000 END @ 2016-12-24 04:00:11.653637, training accuracy 1.00000, ave validation accuracy 0.83603\n",
      "STEP   57000 END @ 2016-12-24 04:01:06.322599, training accuracy 1.00000, ave validation accuracy 0.83586\n",
      "STEP   58000 END @ 2016-12-24 04:02:01.020622, training accuracy 1.00000, ave validation accuracy 0.83581\n",
      "<< hourly save at ckpt_model_05_run01/hourly/model-58100 and pickle_model_05_run01 >>\n",
      "STEP   59000 END @ 2016-12-24 04:03:00.829134, training accuracy 1.00000, ave validation accuracy 0.83625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-feafc4fc8124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinued\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/kumiko/cifar10/helper_functions.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(continued, graph_variables, accuracy_log, train_data, train_labels, validation_data, validation_labels)\u001b[0m\n\u001b[1;32m    251\u001b[0m             _, summary = sess.run([graph_variables['optimizer'], graph_variables['summarizer']], \n\u001b[1;32m    252\u001b[0m                                   feed_dict={graph_variables['data']: batch_data, graph_variables['labels']: batch_labels,\n\u001b[0;32m--> 253\u001b[0;31m                                              graph_variables['keep_prob']: accuracy_log['variables']['dropout_train_keep_prob'], graph_variables['is_training']: True})\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_every'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train(continued, graph_variables, accuracy_log, train_data, train_labels, validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< test accuracy 0.82620 >>\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "test_accuracy(graph_variables, accuracy_log, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
